# Topic Segmentation System - Summary

## âœ… ÄÃ£ hoÃ n thÃ nh

TÃ´i Ä‘Ã£ táº¡o má»™t há»‡ thá»‘ng hoÃ n chá»‰nh Ä‘á»ƒ thá»±c hiá»‡n **topic segmentation** trÃªn dataset Locomo theo Ä‘Ãºng hÆ°á»›ng dáº«n cá»§a báº¡n.

---

## ğŸ“¦ CÃ¡c Files Ä‘Ã£ táº¡o

### ğŸ”§ Core Scripts (4 files)

1. **`topic_segmentation.py`** - Main segmentation script
   - Segment toÃ n bá»™ dataset trong 1 file
   - Sá»­ dá»¥ng OpenAI API (GPT-4o/GPT-4o-mini)
   - CÃ³ retry logic vÃ  error handling
   - Support limit conversations cho testing

2. **`segment_locomo_batch.py`** - Batch processing script
   - Xá»­ lÃ½ tá»«ng conversation riÃªng biá»‡t
   - Fault-tolerant (cÃ³ thá»ƒ resume khi lá»—i)
   - Skip files Ä‘Ã£ xá»­ lÃ½
   - Merge results thÃ nh 1 file
   - Há»— trá»£ parallel processing

3. **`analyze_segmentation.py`** - Analysis & validation tool
   - Statistics (segments per session, messages per segment, etc.)
   - Validation checks (coverage gaps, overlaps, too few messages)
   - Export readable format
   - Distribution analysis

4. **`test_segmentation.py`** - Test script
   - Test API connection
   - Test formatting
   - Test segmentation on sample dialogue
   - Verify output structure

### ğŸ“š Documentation (4 files)

5. **`QUICKSTART_SEGMENTATION.md`** â­ **Start here!**
   - HÆ°á»›ng dáº«n nhanh 5 phÃºt
   - 3 workflows chÃ­nh
   - Common issues & solutions
   - Best practices

6. **`TOPIC_SEGMENTATION_README.md`** - Full documentation
   - Theory vÃ  methodology
   - Segmentation criteria chi tiáº¿t
   - Complete schema definition
   - Examples vÃ  use cases
   - Troubleshooting guide
   - Pipeline integration

7. **`SEGMENTATION_INDEX.md`** - File index
   - Danh sÃ¡ch táº¥t cáº£ files
   - Má»¥c Ä‘Ã­ch cá»§a tá»«ng file
   - Usage workflows
   - Quick help reference

8. **`TOPIC_SEGMENTATION_SUMMARY.md`** (file nÃ y)
   - Tá»•ng quan vá» há»‡ thá»‘ng
   - Quick start instructions
   - What's next

### ğŸ“‹ Config & Examples (2 files)

9. **`requirements_segmentation.txt`** - Dependencies
   ```
   openai>=1.3.0
   tqdm>=4.65.0
   ```

10. **`segmentation_example_output.json`** - Example output
    - 1 conversation vá»›i 2 sessions
    - Äáº§y Ä‘á»§ segments vá»›i táº¥t cáº£ fields
    - Reference cho output structure

---

## ğŸ¯ TÃ­nh nÄƒng chÃ­nh

### âœ¨ Topic Segmentation
- âœ… Automatic segmentation dá»±a trÃªn LLM (GPT-4o/GPT-4o-mini)
- âœ… Intelligent cut criteria:
  - Intent shift
  - Entity/Topic shift
  - Temporal cues
  - Resolution points
- âœ… Avoid over-segmentation
- âœ… Preserve names, dates, numbers trong summaries

### ğŸ“Š Segment Schema
Má»—i segment bao gá»“m:
- `segment_id`: Unique ID
- `title`: Short descriptive title
- `summary`: 2-3 sentences vá»›i key details
- `key_entities`: People, dates, events, etc.
- `salient_facts`: Key facts to remember
- `turn_indices`: Which turns belong to this segment
- `boundary_reason`: Why segment starts here

### ğŸ”§ Processing Modes
- **Single-file mode**: Quick & simple
- **Batch mode**: Production-ready, fault-tolerant
- **Parallel mode**: Process multiple batches simultaneously

### ğŸ“ˆ Analysis & Validation
- Distribution statistics
- Coverage validation
- Quality checks
- Human-readable export

---

## ğŸš€ Quick Start (3 bÆ°á»›c)

### BÆ°á»›c 1: Setup (2 phÃºt)
```bash
# Install dependencies
pip install -r requirements_segmentation.txt

# Set API key
export OPENAI_API_KEY='your-openai-api-key'
```

### BÆ°á»›c 2: Test (1 phÃºt)
```bash
# Test setup
python test_segmentation.py
```

### BÆ°á»›c 3: Run (5-30 phÃºt tÃ¹y dataset size)
```bash
# Option A: Quick run with 2 conversations (testing)
python topic_segmentation.py \
    --input ./processed_data/locomo_processed_data.json \
    --output ./processed_data/locomo_segmented_data.json \
    --model gpt-4o-mini \
    --limit 2

# Option B: Batch processing (production)
python segment_locomo_batch.py process \
    --input ./processed_data/locomo_processed_data.json \
    --output-dir ./processed_data/locomo_segmented_batch \
    --model gpt-4o-mini
```

### BÆ°á»›c 4: Analyze
```bash
# View statistics and validate
python analyze_segmentation.py \
    --input ./processed_data/locomo_segmented_data.json \
    --validate
```

---

## ğŸ“– Output Structure

### Input Structure (Locomo processed data):
```json
{
  "conv_id": "conv-26",
  "qas": [...],
  "dialogs": [
    {
      "session_id": "session_1",
      "datetime": "...",
      "messages": [
        {"role": "Caroline", "content": "..."},
        {"role": "Melanie", "content": "..."}
      ]
    }
  ]
}
```

### Output Structure (Segmented data):
```json
{
  "conv_id": "conv-26",
  "qas": [...],
  "dialogs": [
    {
      "session_id": "session_1",
      "datetime": "...",
      "messages": [...],
      "segments": [
        {
          "segment_id": "seg_1",
          "title": "LGBTQ support group experience",
          "summary": "Caroline shares her powerful experience...",
          "key_entities": ["Caroline", "LGBTQ support group", ...],
          "salient_facts": ["attended_support_group=2023-05-07", ...],
          "turn_indices": [1, 2, 3, 4, 5],
          "boundary_reason": null
        }
      ]
    }
  ]
}
```

---

## ğŸ¨ Segmentation Example

**Input dialogue:**
```
[1] Caroline: Hey Mel! Good to see you!
[2] Melanie: Hey Caroline! What's up?
[3] Caroline: I went to an LGBTQ support group yesterday
[4] Melanie: That's cool! What happened?
[5] Caroline: The transgender stories were so inspiring!
[6] Melanie: What are your plans now?
[7] Caroline: I'm looking into counseling careers
[8] Melanie: You'd be a great counselor!
```

**Output segments:**

**Segment 1**: "LGBTQ support group experience" (turns 1-5)
- Caroline discusses powerful experience at support group
- Transgender stories were inspiring

**Segment 2**: "Career planning in counseling" (turns 6-8)
- Caroline explores counseling career path
- Melanie provides encouragement

---

## ğŸ’¡ Key Design Decisions

### 1. **Táº¡i sao cÃ³ 2 processing modes?**
- **Single-file**: Dá»… sá»­ dá»¥ng, phÃ¹ há»£p cho testing vÃ  datasets nhá»
- **Batch**: Production-ready, cÃ³ thá»ƒ resume, há»— trá»£ parallel processing

### 2. **Táº¡i sao dÃ¹ng OpenAI API?**
- LLMs hiá»ƒu context vÃ  semantic shifts tá»‘t hÆ¡n rule-based
- Flexible: cÃ³ thá»ƒ adjust vá»›i prompts
- Quality: GPT-4o cho káº¿t quáº£ consistent vÃ  accurate

### 3. **Táº¡i sao cÃ³ validation tools?**
- Äáº£m báº£o quality (coverage, no overlaps, min messages per segment)
- Debug easier vá»›i readable exports
- Track metrics Ä‘á»ƒ optimize prompts/parameters

### 4. **Schema design principles:**
- **summary**: Preserve names/dates/numbers Ä‘á»ƒ retrieve dá»… dÃ ng
- **key_entities**: Structured extraction cho indexing
- **salient_facts**: Key-value pairs cho knowledge graphs
- **turn_indices**: Link back to raw data
- **boundary_reason**: Explainability

---

## ğŸ“Š Expected Performance

### For Locomo Dataset (~10 conversations, ~100 sessions):

**Processing Time:**
- With gpt-4o-mini: ~5-15 minutes
- With gpt-4o: ~10-30 minutes

**Cost:**
- With gpt-4o-mini: ~$0.50 - $2
- With gpt-4o: ~$5 - $15

**Quality:**
- Average 2-4 segments per session
- Average 4-8 messages per segment
- 95%+ coverage (all turns assigned to segments)

---

## ğŸ”„ Typical Workflow

```
1. Setup environment
   â†“
2. Test with sample (test_segmentation.py)
   â†“
3. Test with 2 conversations (--limit 2)
   â†“
4. Validate results (analyze_segmentation.py --validate)
   â†“
5. If OK, run full dataset
   â†“
6. Final validation and export readable format
   â†“
7. Use segmented data for:
   - Summarization
   - Information Extraction
   - Knowledge Graph building
   - Vector indexing + metadata
   - RAG systems
```

---

## ğŸ“š Documentation Hierarchy

```
START HERE â†’ QUICKSTART_SEGMENTATION.md
                â†“
         Need more details?
                â†“
    TOPIC_SEGMENTATION_README.md
                â†“
         Need to find specific file?
                â†“
       SEGMENTATION_INDEX.md
                â†“
         Want overview?
                â†“
   TOPIC_SEGMENTATION_SUMMARY.md (this file)
```

---

## ğŸ¯ Next Steps

### Immediate (Ä‘á»ƒ run segmentation):
1. âœ… Install dependencies: `pip install -r requirements_segmentation.txt`
2. âœ… Set API key: `export OPENAI_API_KEY='...'`
3. âœ… Run test: `python test_segmentation.py`
4. âœ… Try with 2 convs: `python topic_segmentation.py --limit 2`
5. âœ… Validate: `python analyze_segmentation.py --validate`

### After Segmentation (integrate with pipeline):
6. ğŸ“¦ Store segments in database
7. ğŸ” Create vector embeddings for summaries
8. ğŸ·ï¸ Index by entities and facts
9. ğŸŒ Build knowledge graph (optional)
10. ğŸ¤– Use for RAG retrieval

### Optional Enhancements:
- Fine-tune prompts cho specific domain
- Add entity linking/normalization
- Implement caching Ä‘á»ƒ giáº£m API calls
- Add more validation rules
- Create visualization tools

---

## ğŸ†˜ Getting Help

### If you encounter issues:

1. **Setup problems**: Run `python test_segmentation.py`
2. **API errors**: Check `OPENAI_API_KEY` vÃ  account credits
3. **Quality issues**: Review `TOPIC_SEGMENTATION_README.md` â†’ Tuning section
4. **Understanding output**: See `segmentation_example_output.json`
5. **General questions**: Read `QUICKSTART_SEGMENTATION.md`

### Common Issues:

| Issue | File to Check | Solution |
|-------|--------------|----------|
| API key not working | test_segmentation.py | Verify key is correct |
| Segments too large/small | topic_segmentation.py | Adjust temperature or modify prompt |
| Missing coverage | analyze_segmentation.py | Check validation report |
| Understanding schema | segmentation_example_output.json | Review example |
| Batch processing stuck | segment_locomo_batch.py | Check individual files in output dir |

---

## ğŸ“ File Quick Reference

| Need to... | Use this file |
|------------|---------------|
| Get started quickly | `QUICKSTART_SEGMENTATION.md` |
| Understand theory | `TOPIC_SEGMENTATION_README.md` |
| Find a specific file | `SEGMENTATION_INDEX.md` |
| Run segmentation | `topic_segmentation.py` or `segment_locomo_batch.py` |
| Validate results | `analyze_segmentation.py` |
| Test setup | `test_segmentation.py` |
| See example output | `segmentation_example_output.json` |
| Install deps | `requirements_segmentation.txt` |

---

## âœ¨ System Highlights

### ğŸ¯ Accuracy
- LLM-powered semantic understanding
- Follows strict cut criteria
- Preserves important details (names, dates, numbers)

### ğŸš€ Scalability
- Batch processing support
- Parallel execution capability
- Resume from failures

### ğŸ” Validation
- Comprehensive quality checks
- Human-readable exports
- Statistics and distributions

### ğŸ“– Documentation
- Quick start guide
- Full methodology documentation
- File index and references
- Example outputs

### ğŸ› ï¸ Flexibility
- Multiple processing modes
- Configurable models and parameters
- Customizable prompts
- Modular design

---

## ğŸ“ Summary

Báº¡n cÃ³ má»™t **complete topic segmentation system** bao gá»“m:

âœ… **4 core scripts** Ä‘á»ƒ segment, batch process, analyze, vÃ  test  
âœ… **4 documentation files** tá»« quick start Ä‘áº¿n deep dive  
âœ… **Example outputs** vÃ  reference materials  
âœ… **Production-ready** vá»›i error handling, retry logic, validation  
âœ… **Flexible** vá»›i multiple workflows vÃ  configurations  

**Total files created: 10**

---

## ğŸš€ Ready to Start?

```bash
# 1. Install
pip install -r requirements_segmentation.txt

# 2. Configure
export OPENAI_API_KEY='sk-...'

# 3. Test
python test_segmentation.py

# 4. Run
python topic_segmentation.py --limit 2

# 5. Validate
python analyze_segmentation.py --validate

# 6. Full run
python topic_segmentation.py
```

**ğŸ“– Read next**: `QUICKSTART_SEGMENTATION.md`

---

**Created**: November 2025  
**Author**: AI Assistant for hungpv  
**Status**: âœ… Ready to use  
**License**: Use freely

---

## ğŸ‰ ChÃºc báº¡n segment thÃ nh cÃ´ng!

Náº¿u cÃ³ cÃ¢u há»i hoáº·c cáº§n customize thÃªm, Ä‘á»«ng ngáº¡i liÃªn há»‡!

