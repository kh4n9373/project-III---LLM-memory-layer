# Topic Segmentation - File Index

Index cá»§a táº¥t cáº£ cÃ¡c files liÃªn quan Ä‘áº¿n topic segmentation cho Locomo dataset.

---

## ğŸ“š Documentation Files

### 1. `QUICKSTART_SEGMENTATION.md` â­ **Báº®T Äáº¦U Táº I ÄÃ‚Y**
- **Má»¥c Ä‘Ã­ch**: HÆ°á»›ng dáº«n nhanh Ä‘á»ƒ báº¯t Ä‘áº§u (5-10 phÃºt)
- **Ná»™i dung**: Setup, cÃ¡c cÃ¡ch cháº¡y, workflows phá»• biáº¿n
- **DÃ nh cho**: NgÆ°á»i dÃ¹ng muá»‘n báº¯t Ä‘áº§u nhanh

### 2. `TOPIC_SEGMENTATION_README.md`
- **Má»¥c Ä‘Ã­ch**: Documentation Ä‘áº§y Ä‘á»§ vÃ  chi tiáº¿t
- **Ná»™i dung**: Theory, schema, examples, troubleshooting, best practices
- **DÃ nh cho**: TÃ¬m hiá»ƒu sÃ¢u vá» segmentation methodology

### 3. `SEGMENTATION_INDEX.md` (file nÃ y)
- **Má»¥c Ä‘Ã­ch**: Tá»•ng quan táº¥t cáº£ cÃ¡c files
- **Ná»™i dung**: Danh sÃ¡ch files, má»¥c Ä‘Ã­ch, usage
- **DÃ nh cho**: Navigation vÃ  reference

---

## ğŸ”§ Core Scripts

### 4. `topic_segmentation.py` â­ **MAIN SCRIPT**
- **Má»¥c Ä‘Ã­ch**: Script chÃ­nh Ä‘á»ƒ cháº¡y topic segmentation
- **Input**: `locomo_processed_data.json`
- **Output**: `locomo_segmented_data.json`
- **Usage**:
  ```bash
  python topic_segmentation.py \
      --input ./processed_data/locomo_processed_data.json \
      --output ./output/segmentation/locomo_segmented_data.json \
      --limit 1
  ```
- **Features**:
  - Single-file processing
  - Automatic segmentation vá»›i LLM
  - Retry logic
  - Progress tracking
- **DÃ nh cho**: Quick runs, testing, small datasets

### 5. `segment_locomo_batch.py` â­ **BATCH SCRIPT**
- **Má»¥c Ä‘Ã­ch**: Batch processing vá»›i fault tolerance
- **Input**: `locomo_processed_data.json`
- **Output**: Individual files per conversation + merged file
- **Usage**:
  ```bash
  # Process
  python segment_locomo_batch.py process \
      --input ./processed_data/locomo_processed_data.json \
      --output-dir ./processed_data/locomo_segmented_batch \
      --start 0 --end 10
  
  # Merge
  python segment_locomo_batch.py merge \
      --batch-dir ./processed_data/locomo_segmented_batch \
      --output ./processed_data/locomo_segmented_merged.json
  ```
- **Features**:
  - Process conversations individually
  - Skip already processed files
  - Exponential backoff retry
  - Resume capability
  - Merge results
- **DÃ nh cho**: Production, large datasets, parallel processing

### 6. `analyze_segmentation.py`
- **Má»¥c Ä‘Ã­ch**: Analyze vÃ  validate segmentation results
- **Input**: Segmented data JSON
- **Output**: Statistics, validation report, readable export
- **Usage**:
  ```bash
  # Statistics
  python analyze_segmentation.py --input ./processed_data/locomo_segmented_data.json
  
  # Validate
  python analyze_segmentation.py --input ./processed_data/locomo_segmented_data.json --validate
  
  # Export readable
  python analyze_segmentation.py \
      --input ./processed_data/locomo_segmented_data.json \
      --export ./analysis/segments.txt \
      --max-export 5
  ```
- **Features**:
  - Distribution statistics
  - Validation checks (coverage, overlaps, etc.)
  - Human-readable export
  - Quality metrics
- **DÃ nh cho**: Quality assurance, debugging, reporting

### 7. `test_segmentation.py`
- **Má»¥c Ä‘Ã­ch**: Test script Ä‘á»ƒ verify setup
- **Input**: Hardcoded test dialogue
- **Output**: Console output + `test_segmentation_output.json`
- **Usage**:
  ```bash
  python test_segmentation.py
  ```
- **Features**:
  - Test dialogue formatting
  - Test LLM segmentation
  - Validate API connection
  - Check output structure
- **DÃ nh cho**: Initial setup verification, debugging

---

## ğŸ“‹ Configuration Files

### 8. `requirements_segmentation.txt`
- **Má»¥c Ä‘Ã­ch**: Python dependencies
- **Ná»™i dung**:
  ```
  openai>=1.3.0
  tqdm>=4.65.0
  ```
- **Usage**:
  ```bash
  pip install -r requirements_segmentation.txt
  ```

---

## ğŸ“Š Example Files

### 9. `segmentation_example_output.json`
- **Má»¥c Ä‘Ã­ch**: Example cá»§a output structure
- **Ná»™i dung**: 1 conversation vá»›i 2 sessions Ä‘Ã£ Ä‘Æ°á»£c segmented
- **DÃ nh cho**: Understanding output schema, reference

---

## ğŸ“ Directory Structure

```
memory_data/
â”‚
â”œâ”€â”€ Documentation
â”‚   â”œâ”€â”€ QUICKSTART_SEGMENTATION.md          â­ Start here
â”‚   â”œâ”€â”€ TOPIC_SEGMENTATION_README.md        Full docs
â”‚   â””â”€â”€ SEGMENTATION_INDEX.md               This file
â”‚
â”œâ”€â”€ Core Scripts
â”‚   â”œâ”€â”€ topic_segmentation.py               â­ Main script
â”‚   â”œâ”€â”€ segment_locomo_batch.py             â­ Batch script
â”‚   â”œâ”€â”€ analyze_segmentation.py             Analysis tool
â”‚   â””â”€â”€ test_segmentation.py                Test script
â”‚
â”œâ”€â”€ Config & Examples
â”‚   â”œâ”€â”€ requirements_segmentation.txt       Dependencies
â”‚   â””â”€â”€ segmentation_example_output.json    Example output
â”‚
â””â”€â”€ Data Directories
    â””â”€â”€ processed_data/
        â”œâ”€â”€ locomo_processed_data.json              Input
        â”œâ”€â”€ locomo_segmented_data.json              Output (main script)
        â”œâ”€â”€ locomo_segmented_test.json              Test output
        â”œâ”€â”€ locomo_segmented_batch/                 Batch outputs
        â”‚   â”œâ”€â”€ locomo_conv-26_segmented.json
        â”‚   â”œâ”€â”€ locomo_conv-30_segmented.json
        â”‚   â””â”€â”€ ...
        â””â”€â”€ locomo_segmented_merged.json            Merged batch output
```

---

## ğŸ¯ Usage Workflows

### Workflow 1: Quick Test & Run
**Files**: `test_segmentation.py` â†’ `topic_segmentation.py` â†’ `analyze_segmentation.py`

```bash
# 1. Test setup
python test_segmentation.py

# 2. Test with 2 conversations
python topic_segmentation.py --limit 2 --model gpt-4o-mini

# 3. Analyze results
python analyze_segmentation.py --validate

# 4. If OK, run full
python topic_segmentation.py --model gpt-4o-mini
```

### Workflow 2: Production Batch Processing
**Files**: `segment_locomo_batch.py` â†’ `analyze_segmentation.py`

```bash
# 1. Process in batches
python segment_locomo_batch.py process --start 0 --end 5
python segment_locomo_batch.py process --start 5

# 2. Merge results
python segment_locomo_batch.py merge

# 3. Validate
python analyze_segmentation.py \
    --input ./processed_data/locomo_segmented_merged.json \
    --validate

# 4. Export readable
python analyze_segmentation.py \
    --input ./processed_data/locomo_segmented_merged.json \
    --export ./analysis/segments_readable.txt
```

### Workflow 3: Parallel Processing
**Files**: `segment_locomo_batch.py` (multiple terminals)

```bash
# Terminal 1
python segment_locomo_batch.py process --start 0 --end 3

# Terminal 2
python segment_locomo_batch.py process --start 3 --end 6

# Terminal 3
python segment_locomo_batch.py process --start 6

# After all complete
python segment_locomo_batch.py merge
```

---

## ğŸ”‘ Key Features by File

| File | Segmentation | Analysis | Batch | Test | Docs |
|------|-------------|----------|-------|------|------|
| `topic_segmentation.py` | âœ… | âŒ | âŒ | âŒ | âŒ |
| `segment_locomo_batch.py` | âœ… | âŒ | âœ… | âŒ | âŒ |
| `analyze_segmentation.py` | âŒ | âœ… | âŒ | âŒ | âŒ |
| `test_segmentation.py` | âœ… | âŒ | âŒ | âœ… | âŒ |
| `QUICKSTART_SEGMENTATION.md` | âŒ | âŒ | âŒ | âŒ | âœ… |
| `TOPIC_SEGMENTATION_README.md` | âŒ | âŒ | âŒ | âŒ | âœ… |

---

## ğŸ“– Reading Order

### For First-Time Users:
1. `QUICKSTART_SEGMENTATION.md` - Get started quickly
2. `test_segmentation.py` - Run test
3. `topic_segmentation.py` - Try with `--limit 2`
4. `analyze_segmentation.py` - Check results
5. `TOPIC_SEGMENTATION_README.md` - Deep dive when needed

### For Production Use:
1. `TOPIC_SEGMENTATION_README.md` - Understand methodology
2. `segment_locomo_batch.py` - Use batch processing
3. `analyze_segmentation.py` - Validate quality

### For Debugging:
1. `test_segmentation.py` - Verify setup
2. `analyze_segmentation.py --validate` - Check issues
3. `segmentation_example_output.json` - Reference correct structure

---

## ğŸ†˜ Quick Help

**Problem**: Don't know where to start  
**Solution**: Read `QUICKSTART_SEGMENTATION.md`

**Problem**: Want to understand theory  
**Solution**: Read `TOPIC_SEGMENTATION_README.md`

**Problem**: Setup not working  
**Solution**: Run `python test_segmentation.py`

**Problem**: Results look wrong  
**Solution**: Run `python analyze_segmentation.py --validate`

**Problem**: Need example output  
**Solution**: See `segmentation_example_output.json`

**Problem**: Want batch processing  
**Solution**: Use `segment_locomo_batch.py process`

**Problem**: Need readable format  
**Solution**: Use `analyze_segmentation.py --export`

---

## ğŸ“Š File Size Reference

Approximate sizes after processing Locomo dataset (~10 conversations):

- Input: `locomo_processed_data.json` â†’ ~1-2 MB
- Output: `locomo_segmented_data.json` â†’ ~1.5-3 MB
- Batch dir: `locomo_segmented_batch/` â†’ ~1.5-3 MB total
- Readable export: `segments_readable.txt` â†’ ~500 KB - 1 MB

---

## ğŸ“ Learning Path

### Beginner:
1. Install dependencies: `requirements_segmentation.txt`
2. Read: `QUICKSTART_SEGMENTATION.md`
3. Run: `test_segmentation.py`
4. Try: `topic_segmentation.py --limit 2`

### Intermediate:
1. Read: `TOPIC_SEGMENTATION_README.md`
2. Run: Full segmentation with `topic_segmentation.py`
3. Analyze: Use `analyze_segmentation.py`
4. Review: `segmentation_example_output.json`

### Advanced:
1. Use: `segment_locomo_batch.py` for batch processing
2. Customize: Modify prompts in scripts
3. Optimize: Tune model/temperature parameters
4. Integrate: Build pipeline with other tools

---

## ğŸ”„ Version History

**v1.0** (Current)
- Initial release
- Basic segmentation functionality
- Batch processing support
- Analysis and validation tools
- Complete documentation

---

**Last Updated**: November 2025  
**Maintainer**: hungpv

---

**Ready to start?**

```bash
# Step 1: Install
pip install -r requirements_segmentation.txt

# Step 2: Set API key
export OPENAI_API_KEY='your-key'

# Step 3: Test
python test_segmentation.py

# Step 4: Run
python topic_segmentation.py --limit 2
```

ğŸ“– **Next**: Read `QUICKSTART_SEGMENTATION.md` for detailed workflows!

