# üîß Setup v·ªõi .env v√† Gemini

H∆∞·ªõng d·∫´n setup ƒë·ªÉ s·ª≠ d·ª•ng v·ªõi file `.env` v√† c√°c API kh√°c nhau (OpenAI, Gemini, etc.)

---

## üìã B∆∞·ªõc 1: Install dependencies

```bash
pip install -r requirements_segmentation.txt
```

Dependencies bao g·ªìm:
- `openai` - OpenAI client library
- `tqdm` - Progress bars
- `python-dotenv` - Load environment variables t·ª´ .env

---

## üìã B∆∞·ªõc 2: T·∫°o file .env

### Option A: Copy t·ª´ template

```bash
cp env.example .env
```

### Option B: T·∫°o file m·ªõi

T·∫°o file `.env` trong th∆∞ m·ª•c `memory_data/`:

```bash
touch .env
```

---

## üîë B∆∞·ªõc 3: C·∫•u h√¨nh API

M·ªü file `.env` v√† paste c·∫•u h√¨nh c·ªßa b·∫°n:

### üü¢ Cho OpenAI API

```env
# OpenAI GPT-4o-mini
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxx
OPENAI_BASE_URL=
DEFAULT_MODEL=gpt-4o-mini
DEFAULT_TEMPERATURE=0.3
PROCESS_LIMIT=
```

### üîµ Cho Gemini API (OpenAI-compatible)

```env
# Gemini via OpenAI-compatible endpoint
OPENAI_API_KEY=your-gemini-api-key-here
OPENAI_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai/
DEFAULT_MODEL=gemini-1.5-flash
DEFAULT_TEMPERATURE=0.3
PROCESS_LIMIT=2
```

**L∆∞u √Ω**: 
- Gemini API key l·∫•y t·ª´: https://aistudio.google.com/app/apikey
- Model names: `gemini-1.5-flash`, `gemini-1.5-pro`, `gemini-2.0-flash-exp`

### üü£ Cho Local Models (via LiteLLM/LocalAI)

```env
# Local model via LiteLLM
OPENAI_API_KEY=dummy
OPENAI_BASE_URL=http://localhost:8000/v1
DEFAULT_MODEL=local-model-name
DEFAULT_TEMPERATURE=0.3
PROCESS_LIMIT=
```

---

## üéØ B∆∞·ªõc 4: C·∫•u h√¨nh tham s·ªë (Optional)

### DEFAULT_MODEL
Model s·∫Ω ƒë∆∞·ª£c d√πng m·∫∑c ƒë·ªãnh. C√≥ th·ªÉ override v·ªõi `--model`.

**OpenAI models:**
- `gpt-4o-mini` - Nhanh, r·∫ª, quality t·ªët
- `gpt-4o` - Balanced
- `gpt-4-turbo` - Quality cao nh·∫•t
- `gpt-3.5-turbo` - R·∫ª nh·∫•t

**Gemini models:**
- `gemini-1.5-flash` - Nhanh, r·∫ª (khuy√™n d√πng)
- `gemini-1.5-pro` - Quality cao h∆°n
- `gemini-2.0-flash-exp` - Experimental, m·ªõi nh·∫•t

### DEFAULT_TEMPERATURE
Gi√° tr·ªã t·ª´ 0.0 ƒë·∫øn 1.0:
- `0.0-0.3` - Consistent, deterministic (khuy√™n d√πng cho segmentation)
- `0.3-0.7` - Balanced
- `0.7-1.0` - Creative, varied

### PROCESS_LIMIT
Gi·ªõi h·∫°n s·ªë conversations x·ª≠ l√Ω:
- ƒê·ªÉ tr·ªëng = x·ª≠ l√Ω t·∫•t c·∫£
- `2` = ch·ªâ x·ª≠ l√Ω 2 conversations ƒë·∫ßu (t·ªët cho testing)
- `10` = x·ª≠ l√Ω 10 conversations ƒë·∫ßu

---

## ‚úÖ B∆∞·ªõc 5: Test setup

```bash
python test_segmentation.py
```

N·∫øu th·∫•y output gi·ªëng n√†y l√† th√†nh c√¥ng:

```
======================================================================
TOPIC SEGMENTATION TEST
======================================================================

Testing dialogue formatting...

======================================================================
FORMATTED DIALOGUE:
======================================================================
[Turn 1] Caroline: Hey Mel! Good to see you!
[Turn 2] Melanie: Hey Caroline! What's up?
...
======================================================================
‚úÖ Formatting test passed!

Testing segmentation with LLM...
This will make an API call to OpenAI.

======================================================================
SEGMENTATION RESULTS:
======================================================================

üìç Segment 1: LGBTQ support group experience
   ID: seg_1
   Turns: [1, 2, 3, 4, 5]
   ...
```

---

## üöÄ B∆∞·ªõc 6: Ch·∫°y segmentation

### Test v·ªõi 2 conversations tr∆∞·ªõc

```bash
python topic_segmentation.py --limit 2
```

Ho·∫∑c n·∫øu ƒë√£ set `PROCESS_LIMIT=2` trong `.env`:

```bash
python topic_segmentation.py
```

### Ch·∫°y v·ªõi range c·ª• th·ªÉ

```bash
# Conversations 0-4 (5 conversations)
python topic_segmentation.py --start 0 --limit 5

# Conversations 5-9 (5 conversations)
python topic_segmentation.py --start 5 --limit 5
```

### Override model t·ª´ command line

```bash
# D√πng model kh√°c thay v√¨ DEFAULT_MODEL
python topic_segmentation.py --model gemini-1.5-pro --limit 2
```

### Xem configuration tr∆∞·ªõc khi ch·∫°y

Khi ch·∫°y script, b·∫°n s·∫Ω th·∫•y configuration summary:

```
======================================================================
CONFIGURATION
======================================================================
Model: gemini-1.5-flash
Temperature: 0.3
Start index: 0
Limit: 2
Input: ./processed_data/locomo_processed_data.json
Output: ./processed_data/locomo_segmented_data.json
Base URL: https://generativelanguage.googleapis.com/v1beta/openai/
======================================================================
```

---

## üìä V√≠ d·ª• c·∫•u h√¨nh cho datasets l·ªõn

### C·∫•u h√¨nh 1: Test mode (nhanh, r·∫ª)

```env
OPENAI_API_KEY=your-key
OPENAI_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai/
DEFAULT_MODEL=gemini-1.5-flash
DEFAULT_TEMPERATURE=0.3
PROCESS_LIMIT=2
```

```bash
python topic_segmentation.py
# ‚Üí Ch·ªâ x·ª≠ l√Ω 2 conversations v·ªõi Gemini Flash
```

### C·∫•u h√¨nh 2: Production mode (quality cao)

```env
OPENAI_API_KEY=sk-proj-xxxxx
OPENAI_BASE_URL=
DEFAULT_MODEL=gpt-4o
DEFAULT_TEMPERATURE=0.3
PROCESS_LIMIT=
```

```bash
python topic_segmentation.py
# ‚Üí X·ª≠ l√Ω t·∫•t c·∫£ v·ªõi GPT-4o
```

### C·∫•u h√¨nh 3: Batch processing

```env
OPENAI_API_KEY=your-gemini-key
OPENAI_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai/
DEFAULT_MODEL=gemini-1.5-flash
DEFAULT_TEMPERATURE=0.3
PROCESS_LIMIT=
```

```bash
# X·ª≠ l√Ω theo batch
python segment_locomo_batch.py process --start 0 --end 5
python segment_locomo_batch.py process --start 5 --end 10

# Merge k·∫øt qu·∫£
python segment_locomo_batch.py merge
```

---

## üîç Troubleshooting

### ‚ùå Error: "OPENAI_API_KEY not found"

**Nguy√™n nh√¢n**: File `.env` ch∆∞a ƒë∆∞·ª£c t·∫°o ho·∫∑c sai v·ªã tr√≠

**Gi·∫£i ph√°p**:
```bash
# Ki·ªÉm tra file .env c√≥ t·ªìn t·∫°i kh√¥ng
ls -la .env

# N·∫øu kh√¥ng c√≥, copy t·ª´ template
cp env.example .env

# Edit file .env
nano .env
# ho·∫∑c
vim .env
# ho·∫∑c m·ªü b·∫±ng editor y√™u th√≠ch
```

### ‚ùå Error: "Invalid API key"

**Nguy√™n nh√¢n**: API key sai ho·∫∑c h·∫øt h·∫°n

**Gi·∫£i ph√°p**:
- **OpenAI**: Ki·ªÉm tra t·∫°i https://platform.openai.com/api-keys
- **Gemini**: Ki·ªÉm tra t·∫°i https://aistudio.google.com/app/apikey

### ‚ùå Error: "Model not found"

**Nguy√™n nh√¢n**: Model name kh√¥ng ƒë√∫ng v·ªõi API

**Gi·∫£i ph√°p**:
- **V·ªõi Gemini base URL**: D√πng `gemini-1.5-flash`, `gemini-1.5-pro`, etc.
- **V·ªõi OpenAI**: D√πng `gpt-4o-mini`, `gpt-4o`, `gpt-4-turbo`, etc.

### ‚ùå Error: "Connection error"

**Nguy√™n nh√¢n**: Base URL kh√¥ng ƒë√∫ng ho·∫∑c m·∫°ng kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c

**Gi·∫£i ph√°p**:
```bash
# Test connection v·ªõi curl
curl -H "Authorization: Bearer YOUR_API_KEY" \
  https://generativelanguage.googleapis.com/v1beta/openai/models

# Ki·ªÉm tra base URL trong .env
cat .env | grep BASE_URL
```

### ‚ö†Ô∏è Warning: Rate limit

**Gi·∫£i ph√°p**:
```bash
# Gi·∫£m s·ªë l∆∞·ª£ng x·ª≠ l√Ω
python topic_segmentation.py --limit 1

# Ho·∫∑c d√πng batch mode v·ªõi retry
python segment_locomo_batch.py process --retry-delay 2.0
```

---

## üí∞ So s√°nh chi ph√≠

∆Ø·ªõc t√≠nh cho Locomo dataset (~10 conversations, ~1000 messages):

| API | Model | Cost/1M tokens | Estimated Total | Speed |
|-----|-------|----------------|-----------------|-------|
| Gemini | gemini-1.5-flash | $0.075 | **$0.10-0.30** | ‚ö°‚ö°‚ö° |
| Gemini | gemini-1.5-pro | $1.25 | $1.50-4.00 | ‚ö°‚ö° |
| OpenAI | gpt-4o-mini | $0.15 | $0.50-2.00 | ‚ö°‚ö°‚ö° |
| OpenAI | gpt-4o | $2.50 | $5.00-15.00 | ‚ö°‚ö° |
| OpenAI | gpt-4-turbo | $10.00 | $20.00-50.00 | ‚ö° |

**üí° Khuy√™n d√πng**: Gemini Flash ho·∫∑c GPT-4o-mini cho cost/performance t·ªët nh·∫•t

---

## üìù Template .env ƒë·∫ßy ƒë·ªß

```env
# =============================================================================
# TOPIC SEGMENTATION CONFIGURATION
# =============================================================================

# API Key (REQUIRED)
# - For OpenAI: Get from https://platform.openai.com/api-keys
# - For Gemini: Get from https://aistudio.google.com/app/apikey
OPENAI_API_KEY=your-api-key-here

# Base URL (OPTIONAL)
# - Leave empty for OpenAI
# - For Gemini: https://generativelanguage.googleapis.com/v1beta/openai/
# - For local: http://localhost:8000/v1
OPENAI_BASE_URL=

# Model (OPTIONAL - default: gpt-4o-mini)
# OpenAI: gpt-4o-mini, gpt-4o, gpt-4-turbo, gpt-3.5-turbo
# Gemini: gemini-1.5-flash, gemini-1.5-pro, gemini-2.0-flash-exp
DEFAULT_MODEL=gpt-4o-mini

# Temperature (OPTIONAL - default: 0.3)
# Range: 0.0 (deterministic) to 1.0 (creative)
# Recommended: 0.2-0.4 for segmentation
DEFAULT_TEMPERATURE=0.3

# Process Limit (OPTIONAL - default: process all)
# Set a number to limit conversations processed
# Useful for testing or large datasets
# Examples: 2 (test), 10 (small batch), empty (all)
PROCESS_LIMIT=

# =============================================================================
# EXAMPLES
# =============================================================================

# Example 1: OpenAI GPT-4o-mini (recommended for production)
# OPENAI_API_KEY=sk-proj-xxxxx
# OPENAI_BASE_URL=
# DEFAULT_MODEL=gpt-4o-mini
# PROCESS_LIMIT=

# Example 2: Gemini Flash (cheap & fast, good for testing)
# OPENAI_API_KEY=your-gemini-key
# OPENAI_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai/
# DEFAULT_MODEL=gemini-1.5-flash
# PROCESS_LIMIT=2

# Example 3: Local model via LiteLLM
# OPENAI_API_KEY=dummy
# OPENAI_BASE_URL=http://localhost:8000/v1
# DEFAULT_MODEL=llama-3-70b
# PROCESS_LIMIT=
```

---

## ‚úÖ Checklist

Sau khi setup xong, check list n√†y:

- [ ] ƒê√£ install `requirements_segmentation.txt`
- [ ] ƒê√£ t·∫°o file `.env` t·ª´ `env.example`
- [ ] ƒê√£ paste API key v√†o `.env`
- [ ] ƒê√£ set `OPENAI_BASE_URL` (n·∫øu d√πng Gemini ho·∫∑c custom API)
- [ ] ƒê√£ set `DEFAULT_MODEL` ph√π h·ª£p v·ªõi API
- [ ] ƒê√£ set `PROCESS_LIMIT` cho testing
- [ ] ƒê√£ ch·∫°y `python test_segmentation.py` th√†nh c√¥ng
- [ ] ƒê√£ test v·ªõi `--limit 2` th√†nh c√¥ng

---

## üéØ Quick Start Commands

```bash
# 1. Setup
pip install -r requirements_segmentation.txt
cp env.example .env
# ‚Üí Edit .env v·ªõi API key v√† settings c·ªßa b·∫°n

# 2. Test
python test_segmentation.py

# 3. Run v·ªõi limit
python topic_segmentation.py --limit 2

# 4. Validate
python analyze_segmentation.py --validate

# 5. Full run (n·∫øu mu·ªën)
python topic_segmentation.py
```

---

**Xong! B·∫°n ƒë√£ s·∫µn s√†ng ƒë·ªÉ ch·∫°y topic segmentation v·ªõi .env config** üöÄ

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ, check ph·∫ßn Troubleshooting ·ªü tr√™n ho·∫∑c ch·∫°y `python test_segmentation.py` ƒë·ªÉ debug.

